# -*- coding: utf-8 -*-
"""malaria_cell.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zABC2LWYsg8zoSCVQancxvhpRHAax9PF
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Sequential, Model, load_model
from keras.applications.vgg19 import VGG19
from glob import glob
from keras.layers import Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input

import tensorflow as tf
tf.__version__

image_size=[224,224]
train_data="/content/drive/MyDrive/Dataset/Train"
test_data="/content/drive/MyDrive/Dataset/Test"

vgg19=VGG19(input_shape=image_size+[3], weights="imagenet", include_top= False)

vgg19.summary()

#storing each layer in an address and setting training off.
for layer in vgg19.layers:
  layer.trainable=False

folders=glob("/content/drive/MyDrive/Dataset/Train/*")

folders

x=Flatten()(vgg19.output)

prediction= Dense(len(folders), activation='softmax')(x)
model=Model(inputs=vgg19.input, outputs=prediction)

model.summary()

#to tell the model what loss funtion and optimization method to use, we use model.compile
model.compile(loss="categorical_crossentropy",optimizer="adam", metrics=["accuracy"])

#to read the data we use image data generator to import the data from the dataset
train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
test_datagen=ImageDataGenerator(rescale=1./255)

training_set=train_datagen.flow_from_directory("/content/drive/MyDrive/Dataset/Train",target_size=(224,224),batch_size=32,class_mode="categorical")

training_set

test_set=test_datagen.flow_from_directory("/content/drive/MyDrive/Dataset/Test",target_size=(224,224),batch_size=32,class_mode="categorical")

#fit the model for training and validation
r=model.fit(training_set,validation_data=test_set, epochs=2, steps_per_epoch=len(training_set), validation_steps=len(test_set))

if tf.test.gpu_device_name():
  print("default gpu name: {}", format(tf.test.gpu_device_name()))
else:
  print("install gpu")

plt.plot(r.history['loss'],"r",label='train loss')
plt.plot(r.history['val_loss'],"b",label='train val_loss')
plt.xlabel("epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()
plt.plot(r.history['accuracy'],"orange",label='train accuracy')
plt.plot(r.history['val_accuracy'],"g",label='train val_accuracy')
plt.xlabel("epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

y_pred=model.predict(test_set)

#probability of it being parasite and uninfected respectively
y_pred

# we need the max in the matrix
y_pred=np.argmax(y_pred,axis=1)

#0: infected, 1: uninfected
y_pred

model.save('model_vgg19.h5')

model=load_model("model_vgg19.h5")

def results(data, model):
  img=image.load_img(data, target_size=(224,224,3))
  x=image.img_to_array(img)
  x1=x.astype('float32')/255
  x2=np.expand_dims(x1,axis=0)
  img_data=preprocess_input(x2)
  a=np.argmax(model.predict(img_data),axis=1)
  if a==1:
    print("the patient is uninfected")
  else:
    print("the patient is infected")

data="/content/drive/MyDrive/Dataset/Test/Parasite/C39P4thinF_original_IMG_20150622_110115_cell_115.png"
results(data,model)
