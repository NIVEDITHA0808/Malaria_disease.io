# -*- coding: utf-8 -*-
"""malaria_cell.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zABC2LWYsg8zoSCVQancxvhpRHAax9PF
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Sequential, Model, load_model
from keras.applications.vgg19 import VGG19
from glob import glob
from keras.layers import Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input

import tensorflow as tf
tf.__version__

image_size=[224,224]
train_data="/content/drive/MyDrive/Dataset/Train"
test_data="/content/drive/MyDrive/Dataset/Test"

vgg19=VGG19(input_shape=image_size+[3], weights="imagenet", include_top= False)

vgg19.summary()

#storing each layer in an address and setting training off.
for layer in vgg19.layers:
  layer.trainable=False

folders=glob("/content/drive/MyDrive/Dataset/Train/*")

folders

x=Flatten()(vgg19.output)

prediction= Dense(len(folders), activation='softmax')(x)
model=Model(inputs=vgg19.input, outputs=prediction)

model.summary()

#to tell the model what loss funtion and optimization method to use, we use model.compile
model.compile(loss="categorical_crossentropy",optimizer="adam", metrics=["accuracy"])

#to read the data we use image data generator to import the data from the dataset
train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
test_datagen=ImageDataGenerator(rescale=1./255)

training_set=train_datagen.flow_from_directory("/content/drive/MyDrive/Dataset/Train",target_size=(224,224),batch_size=32,class_mode="categorical")

training_set

test_set=test_datagen.flow_from_directory("/content/drive/MyDrive/Dataset/Test",target_size=(224,224),batch_size=32,class_mode="categorical")

#fit the model for training and validation
r=model.fit(training_set,validation_data=test_set, epochs=2, steps_per_epoch=len(training_set), validation_steps=len(test_set))

# we need the max in the matrix
y_pred=np.argmax(y_pred,axis=1)

#0: infected, 1: uninfected
y_pred

model.save('model_vgg19.h5')

model=load_model("model_vgg19.h5")
# Define a flask app
app = Flask(__name__)

# Model saved with Keras model.save()
MODEL_PATH = 'models/model_vgg19.h5'

# Load your trained model
model._make_predict_function()          # Necessary
# print('Model loaded. Start serving...')

# You can also use pretrained model from Keras
# Check https://keras.io/applications/
#from keras.applications.resnet50 import ResNet50
#model = ResNet50(weights='imagenet')
#model.save('')

def results(data, MODEL_PATH):
  img=image.load_img(data, target_size=(224,224,3))
  x=image.img_to_array(img)
  x1=x.astype('float32')/255
  x2=np.expand_dims(x1,axis=0)
  img_data=preprocess_input(x2)
  a=np.argmax(model.predict(img_data),axis=1)
  if a==1:
    print("the patient is uninfected")
  else:
    print("the patient is infected")

@app.route('/', methods=['GET'])
def index():
    # Main page
    return render_template('index.html')


@app.route('/predict', methods=['GET', 'POST'])
def upload():
    if request.method == 'POST':
        # Get the file from post request
        f = request.files['file']

        # Save the file to ./uploads
        basepath = os.path.dirname(__file__)
        file_path = os.path.join(
            basepath, 'uploads', secure_filename(f.filename))
        f.save(file_path)

        # Make prediction
        preds = results(file_path, model)

        # Process your result for human
        # pred_class = preds.argmax(axis=-1)            # Simple argmax
        pred_class = decode_predictions(preds, top=1)   # ImageNet Decode
        result = str(pred_class[0][0][1])               # Convert to string
        return result
    return None


if __name__ == '__main__':
    app.run(debug=True)
